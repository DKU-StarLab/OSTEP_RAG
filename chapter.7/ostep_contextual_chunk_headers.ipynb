{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chapter 7.1: Contextual Chunk Headers (CCH)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ OSTEP RAG ì‹œìŠ¤í…œì— Contextual Chunk Headers (CCH) ê¸°ë²•ì„ ì ìš©í•˜ì—¬ ê²€ìƒ‰ í’ˆì§ˆì„ ê°œì„ í•˜ëŠ” ë°©ë²•ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
        "\n",
        "## ðŸ“š í•™ìŠµ ëª©í‘œ\n",  
        "- CCH ê°œë… ì´í•´: ì²­í¬ì— ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸(ì±•í„° ì •ë³´) ì¶”ê°€ì˜ ì¤‘ìš”ì„±\n",
        "- ê¸°ì¡´ ì²­í¬ vs CCH ì ìš© ì²­í¬ì˜ ê²€ìƒ‰ ì„±ëŠ¥ ë¹„êµ\n",
        "- CCH ì ìš© FAISS ì¸ë±ìŠ¤ ìƒì„± ë° ì €ìž¥\n",
        "\n",
        "## ðŸ“‹ ì‹¤ìŠµ êµ¬ì„±\n",
        "1) ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜\n",
        "2) ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì²­í¬/ì¸ë±ìŠ¤)\n",
        "3) CCH ê°œë… ì„¤ëª… ë° í—¤ë” ìƒì„±\n",
        "4) ë¹„êµ ì‹¤í—˜: ì¼ë°˜ ê²€ìƒ‰ vs CCH ê²€ìƒ‰\n",
        "5) CCH ì ìš© ì¸ë±ìŠ¤ ìƒì„± ë° ì €ìž¥\n",
        "6) ë°ëª¨: CCH ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "\n",
        "> **í•µì‹¬ ì•„ì´ë””ì–´**: ì²­í¬ì— ìƒìœ„ ì»¨í…ìŠ¤íŠ¸(ì±•í„° ì œëª© ë“±)ë¥¼ í—¤ë”ë¡œ ì¶”ê°€í•˜ë©´, ìž„ë² ë”©ì´ ë” í’ë¶€í•œ ì˜ë¯¸ë¥¼ ë‹´ê²Œ ë˜ì–´ ê²€ìƒ‰ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1ï¸âƒ£ ì„¤ì • ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° ì •ì˜\n",
        "\n",
        "ì´ ì…€ì—ì„œëŠ” ê²½ë¡œ, ëª¨ë¸, ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ë“±ì„ ì •ì˜í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- ê¸°ì¡´ ì‚°ì¶œë¬¼ ê²½ë¡œ (ì²­í¬ JSON, FAISS ì¸ë±ìŠ¤)\n",
        "- CCH ì ìš© í›„ ì €ìž¥í•  ìƒˆ ì¸ë±ìŠ¤ ê²½ë¡œ\n",
        "- ìž„ë² ë”© ëª¨ë¸ ë° ê²€ìƒ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- ì„¤ì •ê°’ì´ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# 1ï¸âƒ£ ì„¤ì • / í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "# ========================================\n",
        "import os\n",
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# ìž¬í˜„ì„±\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ê²½ë¡œ (ê¸°ì¡´ ì‚°ì¶œë¬¼)\n",
        "CHUNK_FILE = \"/home/kbs1102/workspace/OSTEP_RAG/data/chunk/ostep_tok400_ov20.json\"\n",
        "INDEX_FILE = \"/home/kbs1102/workspace/OSTEP_RAG/data/index/ostep_hnsw.index\"\n",
        "INDEX_META_FILE = \"/home/kbs1102/workspace/OSTEP_RAG/data/index/ostep_hnsw_metadata.json\"\n",
        "\n",
        "# CCH ì ìš© í›„ ì €ìž¥ ê²½ë¡œ\n",
        "CCH_INDEX_FILE = \"/home/kbs1102/workspace/OSTEP_RAG/data/index/ostep_hnsw_cch.index\"\n",
        "CCH_META_FILE = \"/home/kbs1102/workspace/OSTEP_RAG/data/index/ostep_hnsw_cch_metadata.json\"\n",
        "\n",
        "# ê²€ìƒ‰ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "TOP_K = 5\n",
        "EF_SEARCH = 64\n",
        "\n",
        "# ìž„ë² ë”© ëª¨ë¸\n",
        "EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "NORMALIZE = True\n",
        "\n",
        "print(f\"ðŸ”§ Device: {DEVICE}\")\n",
        "print(f\"ðŸ“ ì›ë³¸ ì²­í¬: {CHUNK_FILE}\")\n",
        "print(f\"ðŸ“ ì›ë³¸ ì¸ë±ìŠ¤: {INDEX_FILE}\")\n",
        "print(f\"ðŸ“ CCH ì¸ë±ìŠ¤: {CCH_INDEX_FILE}\")\n",
        "print(f\"ðŸ”Ž TOP_K={TOP_K}, efSearch={EF_SEARCH}\")\n",
        "print(f\"ðŸ§  ìž„ë² ë”© ëª¨ë¸: {EMBED_MODEL}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2ï¸âƒ£ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ\n",
        "\n",
        "Chapter 2-4ì—ì„œ ìƒì„±í•œ ì²­í¬ JSONê³¼ FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- ì²­í¬ ë°ì´í„° ë¡œë“œ ë° êµ¬ì¡° í™•ì¸\n",
        "- ê¸°ì¡´ FAISS ì¸ë±ìŠ¤ ë¡œë“œ\n",
        "- ìž„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- ì²­í¬ ê°œìˆ˜ì™€ ìƒ˜í”Œì´ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì²­í¬ ë¡œë“œ\n",
        "print(\"ì²­í¬ ë°ì´í„° ë¡œë“œ ì¤‘...\")\n",
        "with open(CHUNK_FILE, 'r', encoding='utf-8') as f:\n",
        "    CHUNKS = json.load(f)\n",
        "print(f\"âœ“ ì²­í¬ ë¡œë“œ ì™„ë£Œ: {len(CHUNKS)}ê°œ\")\n",
        "\n",
        "# ìƒ˜í”Œ ì¶œë ¥\n",
        "print(\"\\nìƒ˜í”Œ ì²­í¬ êµ¬ì¡°:\")\n",
        "sample = CHUNKS[0]\n",
        "for key, value in sample.items():\n",
        "    if key == 'text':\n",
        "        print(f\"  {key}: {value[:100]}...\")\n",
        "    else:\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# ê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ\n",
        "print(\"\\nê¸°ì¡´ ì¸ë±ìŠ¤ ë¡œë“œ ì¤‘...\")\n",
        "INDEX_ORIGINAL = faiss.read_index(INDEX_FILE)\n",
        "print(f\"âœ“ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {INDEX_ORIGINAL.ntotal}ê°œ ë²¡í„°\")\n",
        "\n",
        "# ìž„ë² ë”© ëª¨ë¸ ë¡œë“œ\n",
        "print(f\"\\nìž„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {EMBED_MODEL}\")\n",
        "from sentence_transformers import SentenceTransformer\n",
        "embed_model = SentenceTransformer(EMBED_MODEL, device=\"cpu\" if DEVICE==\"cpu\" else DEVICE)\n",
        "print(\"âœ“ ìž„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3ï¸âƒ£ CCH ê°œë… ë° í—¤ë” ìƒì„±\n",
        "\n",
        "ì´ ì…€ì—ì„œëŠ” CCHì˜ í•µì‹¬ ê°œë…ì„ ì„¤ëª…í•˜ê³  ì‹¤ì œ í—¤ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "**CCHëž€?**\n",
        "- ê°œë³„ ì²­í¬ëŠ” ì¢…ì¢… ëŒ€ëª…ì‚¬ë‚˜ ì•”ë¬µì  ì°¸ì¡°ë¥¼ í¬í•¨í•˜ì—¬ ë¬¸ë§¥ì´ ë¶€ì¡±í•©ë‹ˆë‹¤\n",
        "- ë¬¸ì œì : \"ì´ ì•Œê³ ë¦¬ì¦˜ì€...\" â†’ ì–´ë–¤ ì•Œê³ ë¦¬ì¦˜ì¸ì§€ ì²­í¬ë§Œìœ¼ë¡œëŠ” ì•Œ ìˆ˜ ì—†ìŒ\n",
        "- í•´ê²°: ì²­í¬ ì•žì— \"Document: [ì±•í„° ì œëª©]\" ê°™ì€ í—¤ë”ë¥¼ ì¶”ê°€\n",
        "- íš¨ê³¼: ìž„ë² ë”©ì´ ë” ì™„ì „í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë‹´ê²Œ ë˜ì–´ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- í—¤ë” ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
        "- ìƒ˜í”Œ ì²­í¬ì˜ í—¤ë” í¬í•¨/ë¯¸í¬í•¨ ë²„ì „ ë¹„êµ\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- í—¤ë”ê°€ ì¶”ê°€ëœ ì²­í¬ ì˜ˆì‹œê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_chunk_header(chunk: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    ì²­í¬ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ í—¤ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "    \n",
        "    Args:\n",
        "        chunk: ì²­í¬ ë”•ì…”ë„ˆë¦¬ (chapter_title, subsection_title ë“± í¬í•¨)\n",
        "    \n",
        "    Returns:\n",
        "        í—¤ë” ë¬¸ìžì—´\n",
        "    \"\"\"\n",
        "    chapter_title = chunk.get('chapter_title', 'Unknown Chapter')\n",
        "    subsection_title = chunk.get('subsection_title')\n",
        "    \n",
        "    header = f\"Document: {chapter_title}\"\n",
        "    if subsection_title:\n",
        "        header += f\" - {subsection_title}\"\n",
        "    \n",
        "    return header\n",
        "\n",
        "def add_header_to_chunk(chunk: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    ì²­í¬ í…ìŠ¤íŠ¸ì— í—¤ë”ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
        "    \n",
        "    Args:\n",
        "        chunk: ì²­í¬ ë”•ì…”ë„ˆë¦¬\n",
        "    \n",
        "    Returns:\n",
        "        í—¤ë” + ì›ë³¸ í…ìŠ¤íŠ¸\n",
        "    \"\"\"\n",
        "    header = create_chunk_header(chunk)\n",
        "    text = chunk.get('text', '')\n",
        "    return f\"{header}\\n\\n{text}\"\n",
        "\n",
        "# ìƒ˜í”Œ ë¹„êµ\n",
        "print(\"=\" * 80)\n",
        "print(\"[ìƒ˜í”Œ ì²­í¬ ë¹„êµ: í—¤ë” ì—†ìŒ vs í—¤ë” ìžˆìŒ]\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "sample_idx = 10\n",
        "sample_chunk = CHUNKS[sample_idx]\n",
        "\n",
        "print(\"\\n[ì›ë³¸ ì²­í¬ (í—¤ë” ì—†ìŒ)]:\")\n",
        "print(sample_chunk['text'][:300] + \"...\")\n",
        "\n",
        "print(\"\\n[CCH ì ìš© ì²­í¬ (í—¤ë” ìžˆìŒ)]:\")\n",
        "cch_text = add_header_to_chunk(sample_chunk)\n",
        "print(cch_text[:300] + \"...\")\n",
        "\n",
        "print(\"\\nðŸ’¡ ì°¨ì´ì : í—¤ë”ê°€ ì²­í¬ì— ëª…ì‹œì ì¸ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4ï¸âƒ£ ë¹„êµ ì‹¤í—˜: ì¼ë°˜ ê²€ìƒ‰ vs CCH ê²€ìƒ‰\n",
        "\n",
        "ì´ ì…€ì—ì„œëŠ” ë™ì¼í•œ ì¿¼ë¦¬ì— ëŒ€í•´ ì¼ë°˜ ê²€ìƒ‰ê³¼ CCH ê²€ìƒ‰ì„ ë¹„êµí•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ì •ì˜\n",
        "- ê¸°ì¡´ ì¸ë±ìŠ¤ë¡œ ê²€ìƒ‰ (í—¤ë” ì—†ìŒ)\n",
        "- CCH í…ìŠ¤íŠ¸ë¡œ ìž„ì‹œ ìž„ë² ë”© ìƒì„± ë° ê²€ìƒ‰\n",
        "- ê²°ê³¼ ë¹„êµ\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- ë‘ ë°©ì‹ì˜ ê²€ìƒ‰ ê²°ê³¼ì™€ ìœ ì‚¬ë„ ì ìˆ˜ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def distance_to_similarity(distances: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"L2 ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ì •ê·œí™”ëœ ë²¡í„° ê°€ì •)\"\"\"\n",
        "    return 1.0 - (distances / 2.0)\n",
        "\n",
        "def search_with_index(query: str, index: faiss.Index, k: int = TOP_K):\n",
        "    \"\"\"FAISS ì¸ë±ìŠ¤ë¡œ ê²€ìƒ‰\"\"\"\n",
        "    faiss.ParameterSpace().set_index_parameter(index, \"efSearch\", EF_SEARCH)\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=NORMALIZE).astype('float32')\n",
        "    D, I = index.search(q_emb, k)\n",
        "    scores = distance_to_similarity(D[0])\n",
        "    return I[0], scores\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
        "TEST_QUERY = \"How does the operating system manage virtual memory?\"\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {TEST_QUERY}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 1) ì¼ë°˜ ê²€ìƒ‰ (í—¤ë” ì—†ìŒ)\n",
        "print(\"\\n[ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ (í—¤ë” ì—†ìŒ)]:\")\n",
        "indices_orig, scores_orig = search_with_index(TEST_QUERY, INDEX_ORIGINAL, k=3)\n",
        "for rank, (idx, score) in enumerate(zip(indices_orig, scores_orig), 1):\n",
        "    if idx >= 0:\n",
        "        chunk = CHUNKS[idx]\n",
        "        print(f\"\\n{rank}. Score: {score:.4f}\")\n",
        "        print(f\"   Chapter: {chunk.get('chapter_title', 'N/A')}\")\n",
        "        print(f\"   Preview: {chunk['text'][:150]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"ðŸ’¡ CCH ë¹„êµë¥¼ ìœ„í•´ì„œëŠ” CCH ì¸ë±ìŠ¤ë¥¼ ë¨¼ì € ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\")\n",
        "print(\"   ë‹¤ìŒ ë‹¨ê³„ì—ì„œ CCH ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5ï¸âƒ£ CCH ì ìš© ì¸ë±ìŠ¤ ìƒì„± ë° ì €ìž¥\n",
        "\n",
        "ì´ ì…€ì—ì„œëŠ” ëª¨ë“  ì²­í¬ì— CCHë¥¼ ì ìš©í•˜ì—¬ ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- ëª¨ë“  ì²­í¬ì— í—¤ë” ì¶”ê°€\n",
        "- CCH ì ìš© í…ìŠ¤íŠ¸ ìž„ë² ë”© ìƒì„±\n",
        "- HNSW ì¸ë±ìŠ¤ ìƒì„± ë° ì €ìž¥\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- CCH ì¸ë±ìŠ¤ ìƒì„± ì§„í–‰ìƒí™©ê³¼ ì €ìž¥ ê²½ë¡œê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n",
        "- ì´ ê³¼ì •ì€ ëª‡ ë¶„ ì†Œìš”ë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"CCH ì ìš© ìž„ë² ë”© ìƒì„± ì¤‘...\")\n",
        "print(f\"ì´ {len(CHUNKS)}ê°œ ì²­í¬ ì²˜ë¦¬\")\n",
        "\n",
        "# ëª¨ë“  ì²­í¬ì— í—¤ë” ì¶”ê°€\n",
        "cch_texts = [add_header_to_chunk(chunk) for chunk in CHUNKS]\n",
        "print(f\"âœ“ í—¤ë” ì¶”ê°€ ì™„ë£Œ: {len(cch_texts)}ê°œ\")\n",
        "\n",
        "# ìž„ë² ë”© ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬)\n",
        "BATCH_SIZE = 128\n",
        "print(f\"\\nìž„ë² ë”© ìƒì„± ì¤‘ (ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE})...\")\n",
        "all_embeddings = []\n",
        "for i in range(0, len(cch_texts), BATCH_SIZE):\n",
        "    batch = cch_texts[i:i+BATCH_SIZE]\n",
        "    batch_emb = embed_model.encode(\n",
        "        batch,\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=NORMALIZE,\n",
        "        show_progress_bar=False\n",
        "    )\n",
        "    all_embeddings.append(batch_emb)\n",
        "    if (i // BATCH_SIZE + 1) % 10 == 0:\n",
        "        print(f\"  ì§„í–‰: {i+len(batch)}/{len(cch_texts)} ì²­í¬\")\n",
        "\n",
        "embeddings = np.vstack(all_embeddings).astype('float32')\n",
        "print(f\"âœ“ ìž„ë² ë”© ìƒì„± ì™„ë£Œ: shape={embeddings.shape}\")\n",
        "\n",
        "# HNSW ì¸ë±ìŠ¤ ìƒì„±\n",
        "print(\"\\nHNSW ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
        "DIM = embeddings.shape[1]\n",
        "M = 32  # HNSW íŒŒë¼ë¯¸í„°\n",
        "EF_CONSTRUCTION = 64\n",
        "\n",
        "index_cch = faiss.IndexHNSWFlat(DIM, M)\n",
        "index_cch.hnsw.efConstruction = EF_CONSTRUCTION\n",
        "index_cch.add(embeddings)\n",
        "print(f\"âœ“ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ: {index_cch.ntotal}ê°œ ë²¡í„°\")\n",
        "\n",
        "# ì €ìž¥\n",
        "print(f\"\\nì¸ë±ìŠ¤ ì €ìž¥ ì¤‘: {CCH_INDEX_FILE}\")\n",
        "os.makedirs(os.path.dirname(CCH_INDEX_FILE), exist_ok=True)\n",
        "faiss.write_index(index_cch, CCH_INDEX_FILE)\n",
        "\n",
        "# ë©”íƒ€ë°ì´í„° ì €ìž¥\n",
        "cch_metadata = {\n",
        "    \"index_type\": \"HNSW\",\n",
        "    \"dimension\": int(DIM),\n",
        "    \"num_vectors\": int(index_cch.ntotal),\n",
        "    \"M\": M,\n",
        "    \"efConstruction\": EF_CONSTRUCTION,\n",
        "    \"model\": EMBED_MODEL,\n",
        "    \"normalized\": NORMALIZE,\n",
        "    \"cch_applied\": True,\n",
        "    \"chunk_file\": CHUNK_FILE\n",
        "}\n",
        "with open(CCH_META_FILE, 'w', encoding='utf-8') as f:\n",
        "    json.dump(cch_metadata, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"âœ“ ë©”íƒ€ë°ì´í„° ì €ìž¥ ì™„ë£Œ: {CCH_META_FILE}\")\n",
        "print(\"\\nðŸŽ‰ CCH ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6ï¸âƒ£ ë°ëª¨: CCH ê¸°ë°˜ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
        "\n",
        "ì´ ì…€ì—ì„œëŠ” CCH ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- CCH ì¸ë±ìŠ¤ë¡œ ë™ì¼í•œ ì¿¼ë¦¬ ê²€ìƒ‰\n",
        "- ì¼ë°˜ ê²€ìƒ‰ ê²°ê³¼ì™€ ë¹„êµ\n",
        "- ê²€ìƒ‰ í’ˆì§ˆ ê°œì„  í™•ì¸\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- CCH ê²€ìƒ‰ ê²°ê³¼ì™€ ì›ë³¸ ê²€ìƒ‰ ê²°ê³¼ì˜ ë¹„êµê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CCH ì¸ë±ìŠ¤ ê²€ìƒ‰\n",
        "print(\"=\" * 80)\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {TEST_QUERY}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\\n[CCH ê²€ìƒ‰ ê²°ê³¼ (í—¤ë” í¬í•¨)]:\")\n",
        "indices_cch, scores_cch = search_with_index(TEST_QUERY, index_cch, k=3)\n",
        "for rank, (idx, score) in enumerate(zip(indices_cch, scores_cch), 1):\n",
        "    if idx >= 0:\n",
        "        chunk = CHUNKS[idx]\n",
        "        print(f\"\\n{rank}. Score: {score:.4f}\")\n",
        "        print(f\"   Chapter: {chunk.get('chapter_title', 'N/A')}\")\n",
        "        print(f\"   Preview: {chunk['text'][:150]}...\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"[ë¹„êµ ê²°ê³¼]\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"ì¼ë°˜ ê²€ìƒ‰ Top-1 ì ìˆ˜: {scores_orig[0]:.4f}\")\n",
        "print(f\"CCH ê²€ìƒ‰ Top-1 ì ìˆ˜: {scores_cch[0]:.4f}\")\n",
        "print(f\"\\nê°œì„ ë„: {(scores_cch[0] - scores_orig[0]):.4f}\")\n",
        "\n",
        "print(\"\\nðŸ’¡ CCHë¥¼ ì ìš©í•˜ë©´ ì²­í¬ê°€ ë” ëª…í™•í•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•˜ê²Œ ë˜ì–´\")\n",
        "print(\"   ì•”ë¬µì  ì°¸ì¡°ë‚˜ ëŒ€ëª…ì‚¬ê°€ ë§Žì€ ì¿¼ë¦¬ì—ì„œ ê²€ìƒ‰ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7ï¸âƒ£ ì¶”ê°€ í…ŒìŠ¤íŠ¸: ë‹¤ì–‘í•œ ì¿¼ë¦¬ë¡œ CCH íš¨ê³¼ í™•ì¸\n",
        "\n",
        "ì´ ì…€ì—ì„œëŠ” ì—¬ëŸ¬ ì¿¼ë¦¬ë¡œ CCHì˜ íš¨ê³¼ë¥¼ ì¶”ê°€ í™•ì¸í•©ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” ë‚´ìš©:**\n",
        "- ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸\n",
        "- ì¼ë°˜ ê²€ìƒ‰ vs CCH ê²€ìƒ‰ ë¹„êµ\n",
        "\n",
        "**ì‹¤í–‰ ê²°ê³¼:**\n",
        "- ê° ì¿¼ë¦¬ë³„ ê²€ìƒ‰ ê²°ê³¼ì™€ ì ìˆ˜ ê°œì„ ë„ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ì¶”ê°€ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬\n",
        "test_queries = [\n",
        "    \"What is the role of the scheduler in an operating system?\",\n",
        "    \"How does paging work in memory management?\",\n",
        "    \"Explain the concept of process synchronization\"\n",
        "]\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"[ì¶”ê°€ ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸]\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for i, query in enumerate(test_queries, 1):\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"ì¿¼ë¦¬ {i}: {query}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # ì¼ë°˜ ê²€ìƒ‰\n",
        "    indices_orig, scores_orig = search_with_index(query, INDEX_ORIGINAL, k=1)\n",
        "    # CCH ê²€ìƒ‰\n",
        "    indices_cch, scores_cch = search_with_index(query, index_cch, k=1)\n",
        "    \n",
        "    print(f\"\\nì¼ë°˜ ê²€ìƒ‰ Top-1:\")\n",
        "    print(f\"  Score: {scores_orig[0]:.4f}\")\n",
        "    print(f\"  Chapter: {CHUNKS[indices_orig[0]].get('chapter_title', 'N/A')}\")\n",
        "    \n",
        "    print(f\"\\nCCH ê²€ìƒ‰ Top-1:\")\n",
        "    print(f\"  Score: {scores_cch[0]:.4f}\")\n",
        "    print(f\"  Chapter: {CHUNKS[indices_cch[0]].get('chapter_title', 'N/A')}\")\n",
        "    \n",
        "    improvement = scores_cch[0] - scores_orig[0]\n",
        "    print(f\"\\nê°œì„ ë„: {improvement:+.4f} ({'â†‘' if improvement > 0 else 'â†“' if improvement < 0 else 'â†’'})\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"âœ… CCH í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8ï¸âƒ£ ìš”ì•½ ë° ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "### í•™ìŠµ ë‚´ìš© ìš”ì•½\n",
        "\n",
        "1. **CCH ê°œë…**: ì²­í¬ì— ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸(ì±•í„° ì œëª© ë“±)ë¥¼ í—¤ë”ë¡œ ì¶”ê°€\n",
        "2. **íš¨ê³¼**: ìž„ë² ë”©ì´ ë” í’ë¶€í•œ ì˜ë¯¸ë¥¼ ë‹´ê²Œ ë˜ì–´ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ\n",
        "3. **êµ¬í˜„**: ëª¨ë“  ì²­í¬ì— í—¤ë”ë¥¼ ì¶”ê°€í•˜ê³  ìƒˆë¡œìš´ FAISS ì¸ë±ìŠ¤ ìƒì„±\n",
        "4. **ê²€ì¦**: ë™ì¼ ì¿¼ë¦¬ì— ëŒ€í•´ ì¼ë°˜ ê²€ìƒ‰ë³´ë‹¤ ë†’ì€ ìœ ì‚¬ë„ ì ìˆ˜ í™•ì¸\n",
        "\n",
        "### CCHì˜ ìž¥ì \n",
        "\n",
        "- âœ… ì•”ë¬µì  ì°¸ì¡°ì™€ ëŒ€ëª…ì‚¬ ë¬¸ì œ í•´ê²°\n",
        "- âœ… ì²­í¬ ë‹¨ë…ìœ¼ë¡œëŠ” ë¶ˆë¶„ëª…í•œ ì»¨í…ìŠ¤íŠ¸ ëª…ì‹œí™”\n",
        "- âœ… ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ\n",
        "- âœ… êµ¬í˜„ì´ ê°„ë‹¨í•˜ê³  ì¶”ê°€ ë¹„ìš© ìµœì†Œí™”\n",
        "\n",
        "### ë‹¤ìŒ ë‹¨ê³„\n",
        "\n",
        "- **Chapter 7.2**: HyDE (ì¿¼ë¦¬ í™•ìž¥ ê¸°ë²•)\n",
        "- **Chapter 7.3**: Reranking (ê²€ìƒ‰ ê²°ê³¼ ìž¬ì •ë ¬)\n",
        "- **Chapter 7.4**: Self-RAG (ìžê¸° í‰ê°€ ê¸°ë°˜ ê²€ìƒ‰)\n",
        "- **Chapter 7.5**: ëª¨ë“  ê¸°ë²• í†µí•©\n",
        "\n",
        "### ìƒì„±ëœ íŒŒì¼\n",
        "\n",
        "- CCH ì ìš© FAISS ì¸ë±ìŠ¤: `/home/kbs1102/workspace/OSTEP_RAG/data/index/ostep_hnsw_cch.index`\n",
        "- ì¸ë±ìŠ¤ ë©”íƒ€ë°ì´í„°: `/home/kbs1102/workspace/OSTEP_RAG/data/index/ostep_hnsw_cch_metadata.json`\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
