{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c95d94b",
   "metadata": {},
   "source": [
    "\n",
    "# Chapter 4: OSTEP ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• (FAISS HNSW)\n",
    "\n",
    "OSTEP ì„ë² ë”© ë²¡í„°ë¡œ HNSW ì¸ë±ìŠ¤ë¥¼ ìƒì„±/ì €ì¥í•˜ê³  ê²€ìƒ‰ í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“š í•™ìŠµ ëª©í‘œ\n",
    "- HNSW ì¸ë±ìŠ¤ êµ¬ì„±ìš”ì†Œì™€ í•µì‹¬ íŒŒë¼ë¯¸í„°(M/efConstruction/efSearch) ì´í•´\n",
    "- ì¸ë±ìŠ¤ ì €ì¥/ë¡œë“œ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ë° í™œìš©ë²• í•™ìŠµ\n",
    "- ì¸ë±ìŠ¤ í’ˆì§ˆ ê²€ì¦ì„ ìœ„í•œ ê°„ë‹¨í•œ ê²€ìƒ‰/ì ìˆ˜í™” ë£¨í‹´ ì‘ì„±\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ êµ¬ì„±\n",
    "- 1ï¸âƒ£ í™˜ê²½ ì„¤ì •: íŒ¨í‚¤ì§€ ì„¤ì¹˜, ê²½ë¡œ/ìƒìˆ˜ ì •ì˜\n",
    "- 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ: ì„ë² ë”©/ì²­í¬ ë¡œë“œ ë° ì¼ì¹˜ì„± ê²€ì¦\n",
    "- 3ï¸âƒ£ Ground Truth: ë¸Œë£¨íŠ¸í¬ìŠ¤ë¡œ ì°¸ê°’ ìƒì„±/ì €ì¥\n",
    "- 4ï¸âƒ£ ì¸ë±ìŠ¤ êµ¬ì¶•/ì €ì¥: HNSW ìƒì„±, íŒŒë¼ë¯¸í„° ì ìš©, íŒŒì¼ ì €ì¥\n",
    "- 5ï¸âƒ£ ê²€ì¦: ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ í›„ ì¿¼ë¦¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "- 6ï¸âƒ£ íŒŒë¼ë¯¸í„° ì‹¤í—˜(ì„ íƒ): ì„±ëŠ¥ ë³€í™” ê´€ì°°\n",
    "\n",
    "> âš ï¸ ì¸ë±ìŠ¤ í¬ê¸°/ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ê³¼ íŒŒë¼ë¯¸í„°ì— ë”°ë¥¸ ì†ë„Â·ì •í™•ë„ trade-offë¥¼ ê³ ë ¤í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb28b889",
   "metadata": {},
   "source": [
    "---\n",
    "## 1ï¸âƒ£ Google Colab í™˜ê²½ ì„¤ì •\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **Google Colabì—ì„œ GPUë¥¼ ì‚¬ìš©**í•˜ì—¬ ì‹¤í–‰í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ğŸ“Œ ì‹¤í–‰ ì „ ì¤€ë¹„ì‚¬í•­\n",
    "1. **ëŸ°íƒ€ì„ ìœ í˜• ì„¤ì •**: ë©”ë‰´ì—ì„œ `ëŸ°íƒ€ì„` â†’ `ëŸ°íƒ€ì„ ìœ í˜• ë³€ê²½` â†’ `GPU` ì„ íƒ\n",
    "2. **ì²« ë²ˆì§¸ ì½”ë“œ ì…€ ì‹¤í–‰**: Google Drive ë§ˆìš´íŠ¸ ë° í•„ìˆ˜ íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜\n",
    "3. **ì‚¬ì „ ì‹¤í–‰ í•„ìš”**: chapter.2 (ì „ì²˜ë¦¬), chapter.3 (ì„ë² ë”©) ì™„ë£Œ\n",
    "\n",
    "> âš ï¸ **ì¤‘ìš”**: GPUë¥¼ ì‚¬ìš©í•˜ë©´ ë²¡í„° ì¸ë±ìŠ¤ êµ¬ì¶• ë° ê²€ìƒ‰ ì†ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4fbc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Google Colab í™˜ê²½ ì„¤ì •\n",
    "# ========================================\n",
    "from google.colab import drive\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Google Drive ë§ˆìš´íŠ¸\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip -q install faiss-cpu sentence-transformers numpy\n",
    "\n",
    "# ê²½ê³  ì–µì œ\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "# GPU ìë™ ê°ì§€\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ”§ Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "BASE_DIR = \"/content/drive/MyDrive/ostep_rag\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\")\n",
    "EMBEDDINGS_FILE = os.path.join(DATA_DIR, \"vector\", \"ostep_tok400_ov20_embeddings.npy\")\n",
    "CHUNK_FILE = os.path.join(DATA_DIR, \"chunk\", \"ostep_tok400_ov20.json\")\n",
    "OUTPUT_DIR = os.path.join(DATA_DIR, \"index\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# HNSW íŒŒë¼ë¯¸í„°\n",
    "M = 32  # ê° ë…¸ë“œë‹¹ ìµœëŒ€ ì—°ê²° ìˆ˜\n",
    "EF_CONSTRUCTION = 200  # ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œ íƒìƒ‰ ë²”ìœ„\n",
    "EF_SEARCH = 40\n",
    "\n",
    "print(\"\\nâœ… í™˜ê²½ ì„¤ì • ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed026de4",
   "metadata": {},
   "source": [
    "---\n",
    "## 2ï¸âƒ£ ë°ì´í„° ë¡œë“œ\n",
    "\n",
    "ì´ ì…€ì—ì„œëŠ” chapter.3ì—ì„œ ìƒì„±í•œ ì„ë² ë”© ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë‚´ìš©:**\n",
    "- NumPy ë°°ì—´ë¡œ ì €ì¥ëœ ì„ë² ë”© ë²¡í„° ë¡œë“œ\n",
    "- JSON íŒŒì¼ë¡œ ì €ì¥ëœ ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "- ë°ì´í„° shape ë° êµ¬ì¡° í™•ì¸\n",
    "\n",
    "**ì‹¤í–‰ ê²°ê³¼:**\n",
    "- ì„ë² ë”© ë²¡í„°ì™€ ë©”íƒ€ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ê³  ê°œìˆ˜ê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b63c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© ë²¡í„° ë¡œë“œ\n",
    "print(f\"Loading embeddings from: {EMBEDDINGS_FILE}\")\n",
    "embeddings = np.load(EMBEDDINGS_FILE)\n",
    "print(f\"âœ“ Embeddings loaded: {embeddings.shape}\")\n",
    "print(f\"  Dtype: {embeddings.dtype}\")\n",
    "\n",
    "# ì›ë³¸ chunk íŒŒì¼ ë¡œë“œ (ì›ë³¸ JSON ì‚¬ìš©)\n",
    "print(f\"\\nLoading chunks from: {CHUNK_FILE}\")\n",
    "with open(CHUNK_FILE, 'r', encoding='utf-8') as f:\n",
    "    chunks = json.load(f)\n",
    "print(f\"âœ“ Chunks loaded: {len(chunks)} entries\")\n",
    "\n",
    "# ë°ì´í„° ì¼ì¹˜ í™•ì¸\n",
    "assert len(embeddings) == len(chunks), \\\n",
    "    f\"Mismatch: {len(embeddings)} embeddings vs {len(chunks)} chunks\"\n",
    "print(f\"âœ“ Data consistency verified\")\n",
    "\n",
    "# ìƒ˜í”Œ chunk ì¶œë ¥\n",
    "print(\"\\nSample chunk (first entry):\")\n",
    "sample = chunks[0]\n",
    "for key, value in sample.items():\n",
    "    if key == 'text':\n",
    "        print(f\"  {key}: {value[:100]}...\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nTotal vectors to index: {len(embeddings)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f92d6",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ Ground Truth ìƒì„±\n",
    "\n",
    "ì´ ì…€ì—ì„œëŠ” í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ì— ëŒ€í•œ ì •í™•í•œ ë‹µë³€(Ground Truth)ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë‚´ìš©:**\n",
    "- 50ê°œì˜ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ë¡œë“œ\n",
    "- Brute-force ê²€ìƒ‰(IndexFlatL2)ìœ¼ë¡œ ê° ì¿¼ë¦¬ì˜ ì •í™•í•œ top-10 ê²°ê³¼ ìƒì„±\n",
    "- Ground truthë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì—¬ ì´í›„ ì‹¤í—˜ì—ì„œ ì¬ì‚¬ìš©\n",
    "\n",
    "**ì‹¤í–‰ ê²°ê³¼:**\n",
    "- Ground truth íŒŒì¼ì´ ìƒì„±ë˜ê³  ì €ì¥ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dad96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    "\n",
    "# Ground Truth ìƒì„± ì„¤ì •\n",
    "QUERIES_FILE = \"../data/documents/test_queries.json\"\n",
    "GT_FILE = Path(OUTPUT_DIR) / \"ostep_queries_gt_k10.npy\"\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "d=384\n",
    "K = 10  # top-k ê²°ê³¼ ì €ì¥\n",
    "\n",
    "print(f\"Loading test queries from: {QUERIES_FILE}\")\n",
    "with open(QUERIES_FILE, 'r', encoding='utf-8') as f:\n",
    "    test_queries = json.load(f)\n",
    "print(f\"âœ“ Loaded {len(test_queries)} test queries\\n\")\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME, device=\"cpu\")\n",
    "print(\"âœ“ Model loaded\\n\")\n",
    "\n",
    "# ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±\n",
    "print(\"Generating query embeddings...\")\n",
    "query_embeddings = model.encode(test_queries, convert_to_numpy=True, normalize_embeddings=True)\n",
    "print(f\"âœ“ Query embeddings generated: {query_embeddings.shape}\\n\")\n",
    "\n",
    "# Brute-force ì¸ë±ìŠ¤ ìƒì„± (ì •í™•í•œ ê²€ìƒ‰ì„ ìœ„í•œ)\n",
    "print(\"Building brute-force index for ground truth...\")\n",
    "gt_index = faiss.IndexFlatL2(d)\n",
    "gt_index.add(embeddings.astype('float32'))\n",
    "print(f\"âœ“ Brute-force index built: {gt_index.ntotal} vectors\\n\")\n",
    "\n",
    "# Ground Truth ê²€ìƒ‰\n",
    "print(f\"Searching ground truth for top-{K} results...\")\n",
    "gt_distances, gt_indices = gt_index.search(query_embeddings.astype('float32'), K)\n",
    "print(f\"âœ“ Ground truth search completed: {gt_indices.shape}\\n\")\n",
    "\n",
    "# Ground Truth ì €ì¥\n",
    "print(f\"Saving ground truth to: {GT_FILE}\")\n",
    "np.save(str(GT_FILE), gt_indices)\n",
    "print(f\"âœ“ Ground truth saved: {GT_FILE}\")\n",
    "\n",
    "# âˆƒ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(\"\\nSample ground truth (first query):\")\n",
    "print(f\"  Query: {test_queries[0][:80]}...\")\n",
    "print(f\"  Top-3 indices: {gt_indices[0][:3]}\")\n",
    "print(f\"  Top-3 chunks:\")\n",
    "for i, idx in enumerate(gt_indices[0][:3]):\n",
    "    chunk = chunks[idx]\n",
    "    print(f\"    {i+1}. [{chunk['chapter_title']}] {chunk['text'][:60]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210e81f8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e5eb30",
   "metadata": {},
   "source": [
    "---\n",
    "## 3ï¸âƒ£ ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "\n",
    "ì´ ì…€ì—ì„œëŠ” FAISS HNSW ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ë²¡í„°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë‚´ìš©:**\n",
    "- HNSW32 ì¸ë±ìŠ¤ ìƒì„± (M=32, ê° ë…¸ë“œë‹¹ ìµœëŒ€ 32ê°œ ì—°ê²°)\n",
    "- efConstruction íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "- ì •ê·œí™”ëœ ë²¡í„° ì¶”ê°€ (L2 distanceê°€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ì™€ ë™ì¼)\n",
    "\n",
    "**ì‹¤í–‰ ê²°ê³¼:**\n",
    "- ì¸ë±ìŠ¤ê°€ ìƒì„±ë˜ê³  ëª¨ë“  ë²¡í„°ê°€ ì¶”ê°€ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = embeddings.shape[1]  # ë²¡í„° ì°¨ì›\n",
    "print(f\"Vector dimension: {d}\")\n",
    "print(f\"\\nBuilding HNSW{M} index...\")\n",
    "\n",
    "# HNSW ì¸ë±ìŠ¤ ìƒì„± (ì˜¬ë°”ë¥¸ í˜•ì‹: \"HNSW32\")\n",
    "index = faiss.index_factory(d, f\"HNSW{M}\")\n",
    "\n",
    "# ì¸ë±ìŠ¤ í’ˆì§ˆ íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "faiss.ParameterSpace().set_index_parameter(index, \"efConstruction\", EF_CONSTRUCTION)\n",
    "faiss.ParameterSpace().set_index_parameter(index, \"efSearch\", EF_SEARCH)\n",
    "\n",
    "print(f\"âœ“ Index created: {index}\")\n",
    "print(f\"  efConstruction: {EF_CONSTRUCTION}\")\n",
    "print(f\"  efSearch: {EF_SEARCH}\")\n",
    "\n",
    "# ë²¡í„° ì¶”ê°€ (float32ë¡œ ë³€í™˜)\n",
    "print(f\"\\nAdding {len(embeddings)} vectors to index...\")\n",
    "index.add(embeddings.astype('float32'))\n",
    "\n",
    "print(f\"âœ“ Index built successfully!\")\n",
    "print(f\"  Total vectors indexed: {index.ntotal}\")\n",
    "print(f\"  Is trained: {index.is_trained}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca2fa54",
   "metadata": {},
   "source": [
    "---\n",
    "## 4ï¸âƒ£ ì¸ë±ìŠ¤ ì €ì¥\n",
    "\n",
    "ì´ ì…€ì—ì„œëŠ” ìƒì„±ëœ ì¸ë±ìŠ¤ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë‚´ìš©:**\n",
    "- FAISS ì¸ë±ìŠ¤ íŒŒì¼(.index) ì €ì¥\n",
    "- ì¸ë±ìŠ¤ ë©”íƒ€ì •ë³´ JSON íŒŒì¼ ì €ì¥\n",
    "\n",
    "**ì‹¤í–‰ ê²°ê³¼:**\n",
    "- ì¸ë±ìŠ¤ íŒŒì¼ì´ ìƒì„±ë˜ê³  ì €ì¥ ê²½ë¡œê°€ ì¶œë ¥ë©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70c424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "INDEX_FILE = Path(OUTPUT_DIR) / \"ostep_hnsw.index\"\n",
    "METADATA_INDEX_FILE = Path(OUTPUT_DIR) / \"ostep_hnsw_metadata.json\"\n",
    "\n",
    "# FAISS ì¸ë±ìŠ¤ ì €ì¥\n",
    "print(f\"Saving index to: {INDEX_FILE}\")\n",
    "faiss.write_index(index, str(INDEX_FILE))\n",
    "print(f\"âœ“ Index saved: {INDEX_FILE}\")\n",
    "\n",
    "# ì¸ë±ìŠ¤ ë©”íƒ€ì •ë³´ ì €ì¥\n",
    "index_info = {\n",
    "    'index_type': f'HNSW{M}',\n",
    "    'num_vectors': index.ntotal,\n",
    "    'vector_dim': d,\n",
    "    'ef_construction': EF_CONSTRUCTION,\n",
    "    'ef_search': EF_SEARCH,\n",
    "    'is_trained': index.is_trained,\n",
    "    'embeddings_source': str(EMBEDDINGS_FILE)\n",
    "}\n",
    "\n",
    "print(f\"\\nSaving index metadata to: {METADATA_INDEX_FILE}\")\n",
    "with open(METADATA_INDEX_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(index_info, f, ensure_ascii=False, indent=2)\n",
    "print(f\"âœ“ Index metadata saved\")\n",
    "\n",
    "# íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "index_size = INDEX_FILE.stat().st_size / (1024 * 1024)  # MB\n",
    "\n",
    "print(f\"\\nFile sizes:\")\n",
    "print(f\"  Index: {index_size:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49354b27",
   "metadata": {},
   "source": [
    "---\n",
    "## 5ï¸âƒ£ ê²€ì¦ - ì¸ë±ìŠ¤ ë¡œë“œ ë° ì¿¼ë¦¬ ê²€ìƒ‰\n",
    "\n",
    "ì´ ì…€ì—ì„œëŠ” ì €ì¥ëœ ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ì‹¤ì œ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì£¼ìš” ë‚´ìš©:**\n",
    "- SentenceTransformer ëª¨ë¸ ë¡œë“œ\n",
    "- ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "- ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì¿¼ë¦¬ ë¬¸ì¥ìœ¼ë¡œ ê²€ìƒ‰\n",
    "- ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ\n",
    "\n",
    "**ì‚¬ìš© ë°©ë²•:**\n",
    "- `query_text` ë³€ìˆ˜ì— ê²€ìƒ‰í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c0b77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SentenceTransformer ëª¨ë¸ ë¡œë“œ\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "device = \"cpu\"\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "print(\"âœ“ Model loaded successfully!\")\n",
    "\n",
    "# 2. ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ\n",
    "print(\"\\nLoading saved index...\")\n",
    "loaded_index = faiss.read_index(str(INDEX_FILE))\n",
    "print(f\"âœ“ Index loaded successfully!\")\n",
    "print(f\"  Total vectors: {loaded_index.ntotal}\")\n",
    "print(f\"  Is trained: {loaded_index.is_trained}\")\n",
    "\n",
    "# 3. ë©”íƒ€ë°ì´í„° ë¡œë“œ\n",
    "with open(METADATA_INDEX_FILE, 'r', encoding='utf-8') as f:\n",
    "    loaded_index_info = json.load(f)\n",
    "\n",
    "print(\"\\nIndex metadata:\")\n",
    "for key, value in loaded_index_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# 4. ê²€ìƒ‰í•  ì¿¼ë¦¬ ë¬¸ì¥ ì…ë ¥\n",
    "query_text = \"How does the operating system handle memory virtualization?\"  # ì—¬ê¸°ì— ê²€ìƒ‰í•  ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš”\n",
    "k = 5  # top-k ê²€ìƒ‰\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(f\"Query: {query_text}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 5. ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜\n",
    "print(f\"\\nEmbedding query text...\")\n",
    "query_embedding = model.encode([query_text], convert_to_numpy=True, normalize_embeddings=True)[0]\n",
    "print(f\"âœ“ Query embedded: {query_embedding.shape}\")\n",
    "\n",
    "# 6. FAISS ì¸ë±ìŠ¤ì—ì„œ ê²€ìƒ‰\n",
    "print(f\"\\nSearching for top-{k} nearest neighbors...\")\n",
    "D, I = loaded_index.search(query_embedding.reshape(1, -1).astype('float32'), k)\n",
    "\n",
    "# 7. ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ ì ìˆ˜ë¡œ ë³€í™˜ (ì •ê·œí™”ëœ ë²¡í„°ì˜ L2 ê±°ë¦¬)\n",
    "# similarity â‰ˆ 1 - (distance/2)\n",
    "scores = 1 - (D[0] / 2)\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Top-{k} Search Results:\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for rank, (idx, score) in enumerate(zip(I[0], scores), 1):\n",
    "    chunk = chunks[idx]\n",
    "    # print(f\"Rank {rank} (Score: {score:.4f}):\")\n",
    "    # print(f\"  chunk ID: {chunk['chunk_id']}\")\n",
    "    # print(f\"  Chapter: {chunk['chapter_title']}\")\n",
    "    # if chunk.get('subsection_title'):\n",
    "    #     print(f\"  Section: {chunk['subsection_title']}\")\n",
    "    \n",
    "    # ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ\n",
    "    text_preview = chunk['text'][:70] if chunk.get('text') else 'N/A'\n",
    "    print(f\"Rank {rank}: {text_preview}...\")\n",
    "\n",
    "print(\"âœ“ Search completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce35284",
   "metadata": {},
   "source": [
    "---\n",
    "## 6ï¸âƒ£ HNSW íŒŒë¼ë¯¸í„° ì‹¤í—˜\n",
    "\n",
    "ì´ ì…€ì—ì„œëŠ” HNSW íŒŒë¼ë¯¸í„°(M, efConstruction, efSearch) ë³€í™”ì— ë”°ë¥¸ ì„±ëŠ¥ì„ ì¸¡ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "**ì¸¡ì • ì§€í‘œ:**\n",
    "- ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œê°„ (ì´ˆ)\n",
    "- ê²€ìƒ‰ ì†ë„ (í‰ê·  latency, ms)\n",
    "- ê²€ìƒ‰ ì •í™•ë„ (Recall@10)\n",
    "\n",
    "**íŒŒë¼ë¯¸í„° ë²”ìœ„:**\n",
    "- M: [8, 16, 32, 48, 64]\n",
    "- efConstruction: [50, 100, 200, 300, 400, 500]\n",
    "- efSearch: [10, 20, 40, 80, 160, 320]\n",
    "\n",
    "âš ï¸ **ì£¼ì˜:** ì´ ì‹¤í—˜ì€ ë§ì€ íŒŒë¼ë¯¸í„° ì¡°í•©ì„ í…ŒìŠ¤íŠ¸í•˜ë¯€ë¡œ ì‹¤í–‰ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89aed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í—˜ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "M_VALUES = [8, 16, 32, 48, 64]\n",
    "EF_CONSTRUCTION_VALUES = [50, 100, 200, 300, 400, 500]\n",
    "EF_SEARCH_VALUES = [10, 20, 40, 80, 160, 320]\n",
    "\n",
    "# Ground Truth ë¡œë“œ\n",
    "print(\"Loading ground truth...\")\n",
    "gt_indices = np.load(str(GT_FILE))\n",
    "print(f\"âœ“ Ground truth loaded: {gt_indices.shape}\\n\")\n",
    "\n",
    "# ì‹¤í—˜ ê²°ê³¼ ì €ì¥ìš©\n",
    "results = []\n",
    "\n",
    "# ì´ ì¡°í•© ìˆ˜ ê³„ì‚°\n",
    "total_combinations = len(M_VALUES) * len(EF_CONSTRUCTION_VALUES) * len(EF_SEARCH_VALUES)\n",
    "print(f\"Total parameter combinations to test: {total_combinations}\")\n",
    "print(f\"Testing {len(test_queries)} queries per combination...\\n\")\n",
    "\n",
    "current = 0\n",
    "for m_val in M_VALUES:\n",
    "    for ef_cons_val in EF_CONSTRUCTION_VALUES:\n",
    "        for ef_search_val in EF_SEARCH_VALUES:\n",
    "            current += 1\n",
    "            print(f\"[{current}/{total_combinations}] M={m_val}, efConstruction={ef_cons_val}, efSearch={ef_search_val}\")\n",
    "            \n",
    "            try:\n",
    "                # 1. ì¸ë±ìŠ¤ êµ¬ì¶•\n",
    "                start_time = time.time()\n",
    "                test_index = faiss.index_factory(d, f\"HNSW{m_val}\")\n",
    "                faiss.ParameterSpace().set_index_parameter(test_index, \"efConstruction\", ef_cons_val)\n",
    "                faiss.ParameterSpace().set_index_parameter(test_index, \"efSearch\", ef_search_val)\n",
    "                test_index.add(embeddings.astype('float32'))\n",
    "                build_time = time.time() - start_time\n",
    "                \n",
    "                # 2. ê²€ìƒ‰ ì„±ëŠ¥ ì¸¡ì •\n",
    "                # efSearch íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •\n",
    "                faiss.ParameterSpace().set_index_parameter(test_index, \"efSearch\", ef_search_val)\n",
    "                \n",
    "                search_latencies = []\n",
    "                all_predicted_indices = []\n",
    "                \n",
    "                for query_emb in query_embeddings:\n",
    "                    start = time.time()\n",
    "                    _, indices = test_index.search(query_emb.reshape(1, -1).astype('float32'), K)\n",
    "                    latency = (time.time() - start) * 1000  # ms\n",
    "                    search_latencies.append(latency)\n",
    "                    all_predicted_indices.append(indices[0])\n",
    "                \n",
    "                avg_latency = np.mean(search_latencies)\n",
    "                \n",
    "                # 3. Recall@10 ê³„ì‚°\n",
    "                recall_scores = []\n",
    "                for gt_idx, pred_idx in zip(gt_indices, all_predicted_indices):\n",
    "                    recall = len(set(gt_idx) & set(pred_idx)) / len(gt_idx)\n",
    "                    recall_scores.append(recall)\n",
    "                \n",
    "                mean_recall = np.mean(recall_scores)\n",
    "                \n",
    "                # ê²°ê³¼ ì €ì¥\n",
    "                results.append({\n",
    "                    'M': m_val,\n",
    "                    'efConstruction': ef_cons_val,\n",
    "                    'efSearch': ef_search_val,\n",
    "                    'build_time': build_time,\n",
    "                    'avg_latency_ms': avg_latency,\n",
    "                    'recall@10': mean_recall\n",
    "                })\n",
    "                \n",
    "                print(f\"  â†’ Build: {build_time:.3f}s, Latency: {avg_latency:.3f}ms, Recall@10: {mean_recall:.4f}\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error: {str(e)}\\n\")\n",
    "\n",
    "print(\"âœ“ All experiments completed!\")\n",
    "print(f\"Total results: {len(results)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e86162",
   "metadata": {},
   "source": [
    "---\n",
    "## 7ï¸âƒ£ ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ë° ìš”ì•½\n",
    "\n",
    "ì‹¤í—˜ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ìš”ì•½ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "import pandas as pd\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "RESULTS_FILE = Path(OUTPUT_DIR) / \"hnsw_experiment_results.json\"\n",
    "print(f\"Saving results to: {RESULTS_FILE}\")\n",
    "df_results.to_json(RESULTS_FILE, orient='records', indent=2)\n",
    "print(f\"âœ“ Results saved\\n\")\n",
    "\n",
    "# ìš”ì•½ í†µê³„ ì¶œë ¥\n",
    "print(\"=\"*70)\n",
    "print(\"Experiment Summary Statistics\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nTotal configurations tested: {len(df_results)}\")\n",
    "print(f\"\\nMetrics Summary:\")\n",
    "print(f\"  Build Time: {df_results['build_time'].mean():.3f}s Â± {df_results['build_time'].std():.3f}s\")\n",
    "print(f\"    Min: {df_results['build_time'].min():.3f}s\")\n",
    "print(f\"    Max: {df_results['build_time'].max():.3f}s\")\n",
    "print(f\"\\n  Search Latency: {df_results['avg_latency_ms'].mean():.3f}ms Â± {df_results['avg_latency_ms'].std():.3f}ms\")\n",
    "print(f\"    Min: {df_results['avg_latency_ms'].min():.3f}ms\")\n",
    "print(f\"    Max: {df_results['avg_latency_ms'].max():.3f}ms\")\n",
    "print(f\"\\n  Recall@10: {df_results['recall@10'].mean():.4f} Â± {df_results['recall@10'].std():.4f}\")\n",
    "print(f\"    Min: {df_results['recall@10'].min():.4f}\")\n",
    "print(f\"    Max: {df_results['recall@10'].max():.4f}\")\n",
    "\n",
    "# Best configurations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Best Configurations by Metric\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nFastest Build Time:\")\n",
    "best_build = df_results.loc[df_results['build_time'].idxmin()]\n",
    "print(f\"  M={best_build['M']}, efConstruction={best_build['efConstruction']}, efSearch={best_build['efSearch']}\")\n",
    "print(f\"  Build: {best_build['build_time']:.3f}s, Latency: {best_build['avg_latency_ms']:.3f}ms, Recall@10: {best_build['recall@10']:.4f}\")\n",
    "\n",
    "print(\"\\nFastest Search:\")\n",
    "best_latency = df_results.loc[df_results['avg_latency_ms'].idxmin()]\n",
    "print(f\"  M={best_latency['M']}, efConstruction={best_latency['efConstruction']}, efSearch={best_latency['efSearch']}\")\n",
    "print(f\"  Build: {best_latency['build_time']:.3f}s, Latency: {best_latency['avg_latency_ms']:.3f}ms, Recall@10: {best_latency['recall@10']:.4f}\")\n",
    "\n",
    "print(\"\\nBest Recall@10:\")\n",
    "best_recall = df_results.loc[df_results['recall@10'].idxmax()]\n",
    "print(f\"  M={best_recall['M']}, efConstruction={best_recall['efConstruction']}, efSearch={best_recall['efSearch']}\")\n",
    "print(f\"  Build: {best_recall['build_time']:.3f}s, Latency: {best_recall['avg_latency_ms']:.3f}ms, Recall@10: {best_recall['recall@10']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49b57b6",
   "metadata": {},
   "source": [
    "---\n",
    "## 8ï¸âƒ£ íŒŒë¼ë¯¸í„°ë³„ ì„±ëŠ¥ ì‹œê°í™”\n",
    "\n",
    "íŒŒë¼ë¯¸í„° ë³€í™”ì— ë”°ë¥¸ ì„±ëŠ¥ ë³€í™”ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ì‹œê°í™” í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "FIGSIZE_M = (18, 5)\n",
    "FIGSIZE_EFCONS = (18, 5)\n",
    "FIGSIZE_EFSEARCH = (12, 5)\n",
    "RECALL_YMIN, RECALL_YMAX = 0.9, 1.003\n",
    "\n",
    "# 1) M ë³„ Figure (Build, Latency, Recall@10)\n",
    "fig_m, axes_m = plt.subplots(1, 3, figsize=FIGSIZE_M)\n",
    "fig_m.suptitle('Effect of M on Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "# M vs Build Time\n",
    "m_build_avg = df_results.groupby('M')['build_time'].mean()\n",
    "axes_m[0].plot(m_build_avg.index, m_build_avg.values, marker='o', linewidth=2, markersize=8)\n",
    "axes_m[0].set_xlabel('M (Max connections)', fontsize=12)\n",
    "axes_m[0].set_ylabel('Build Time (s)', fontsize=12)\n",
    "axes_m[0].set_title('M vs Build Time', fontsize=13, fontweight='bold')\n",
    "axes_m[0].grid(True, alpha=0.3)\n",
    "\n",
    "# M vs Latency\n",
    "m_latency_avg = df_results.groupby('M')['avg_latency_ms'].mean()\n",
    "axes_m[1].plot(m_latency_avg.index, m_latency_avg.values, marker='o', linewidth=2, markersize=8, color='orange')\n",
    "axes_m[1].set_xlabel('M (Max connections)', fontsize=12)\n",
    "axes_m[1].set_ylabel('Avg Latency (ms)', fontsize=12)\n",
    "axes_m[1].set_title('M vs Search Latency', fontsize=13, fontweight='bold')\n",
    "axes_m[1].grid(True, alpha=0.3)\n",
    "\n",
    "# M vs Recall@10\n",
    "m_recall_avg = df_results.groupby('M')['recall@10'].mean()\n",
    "axes_m[2].plot(m_recall_avg.index, m_recall_avg.values, marker='o', linewidth=2, markersize=8, color='green')\n",
    "axes_m[2].set_xlabel('M (Max connections)', fontsize=12)\n",
    "axes_m[2].set_ylabel('Recall@10', fontsize=12)\n",
    "axes_m[2].set_title('M vs Recall@10', fontsize=13, fontweight='bold')\n",
    "axes_m[2].grid(True, alpha=0.3)\n",
    "axes_m[2].set_ylim(RECALL_YMIN, RECALL_YMAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2) efConstruction ë³„ Figure (Build, Recall@10)\n",
    "fig_ec, axes_ec = plt.subplots(1, 3, figsize=FIGSIZE_EFCONS)\n",
    "fig_ec.suptitle('Effect of efConstruction on Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "ef_cons_build_avg = df_results.groupby('efConstruction')['build_time'].mean()\n",
    "axes_ec[0].plot(ef_cons_build_avg.index, ef_cons_build_avg.values, marker='s', linewidth=2, markersize=8)\n",
    "axes_ec[0].set_xlabel('efConstruction', fontsize=12)\n",
    "axes_ec[0].set_ylabel('Build Time (s)', fontsize=12)\n",
    "axes_ec[0].set_title('efConstruction vs Build Time', fontsize=13, fontweight='bold')\n",
    "axes_ec[0].grid(True, alpha=0.3)\n",
    "\n",
    "ef_cons_latency_avg = df_results.groupby('efConstruction')['avg_latency_ms'].mean()\n",
    "axes_ec[1].plot(ef_cons_latency_avg.index, ef_cons_latency_avg.values, marker='o', linewidth=2, markersize=8, color='orange')\n",
    "axes_ec[1].set_xlabel('efConstruction', fontsize=12)\n",
    "axes_ec[1].set_ylabel('Avg Latency (ms)', fontsize=12)\n",
    "axes_ec[1].set_title('efConstruction vs Search Latency', fontsize=13, fontweight='bold')\n",
    "axes_ec[1].grid(True, alpha=0.3)\n",
    "axes_ec[1].set_ylim(0.06, 0.08)\n",
    "\n",
    "ef_cons_recall_avg = df_results.groupby('efConstruction')['recall@10'].mean()\n",
    "axes_ec[2].plot(ef_cons_recall_avg.index, ef_cons_recall_avg.values, marker='s', linewidth=2, markersize=8, color='green')\n",
    "axes_ec[2].set_xlabel('efConstruction', fontsize=12)\n",
    "axes_ec[2].set_ylabel('Recall@10', fontsize=12)\n",
    "axes_ec[2].set_title('efConstruction vs Recall@10', fontsize=13, fontweight='bold')\n",
    "axes_ec[2].grid(True, alpha=0.3)\n",
    "axes_ec[2].set_ylim(RECALL_YMIN, RECALL_YMAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3) efSearch ë³„ Figure (Latency, Recall@10)\n",
    "fig_es, axes_es = plt.subplots(1, 2, figsize=FIGSIZE_EFSEARCH)\n",
    "fig_es.suptitle('Effect of efSearch on Performance', fontsize=16, fontweight='bold')\n",
    "\n",
    "# efSearch vs Latency\n",
    "ef_search_latency = df_results.groupby('efSearch')['avg_latency_ms'].mean()\n",
    "axes_es[0].plot(ef_search_latency.index, ef_search_latency.values, marker='D', linewidth=2, markersize=8, color='red')\n",
    "axes_es[0].set_xlabel('efSearch', fontsize=12)\n",
    "axes_es[0].set_ylabel('Avg Latency (ms)', fontsize=12)\n",
    "axes_es[0].set_title('efSearch vs Search Latency', fontsize=13, fontweight='bold')\n",
    "axes_es[0].grid(True, alpha=0.3)\n",
    "\n",
    "# efSearch vs Recall@10\n",
    "ef_search_recall = df_results.groupby('efSearch')['recall@10'].mean()\n",
    "axes_es[1].plot(ef_search_recall.index, ef_search_recall.values, marker='D', linewidth=2, markersize=8, color='purple')\n",
    "axes_es[1].set_xlabel('efSearch', fontsize=12)\n",
    "axes_es[1].set_ylabel('Recall@10', fontsize=12)\n",
    "axes_es[1].set_title('efSearch vs Recall@10', fontsize=13, fontweight='bold')\n",
    "axes_es[1].grid(True, alpha=0.3)\n",
    "axes_es[1].set_ylim(RECALL_YMIN, RECALL_YMAX)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
